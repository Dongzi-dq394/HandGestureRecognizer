# Hand Gesture Recognition
## Team: 
Mina Lee (ml6543), Dongzi Qu (dq394), Zili Xie (zx979),  Lynn Li (ml6589)
## Description:
Recognize multiple hand gestures from a static image or pre-recorded video sequence from the local file stream.
Interpret the meaning of the hand gestures. For example, ‘V’, thumbs up, ‘OK’, the horn fingers, the fist bump, and the high five.
## Methods: 
* Segmentation
* Background subtraction 
* Active contour
* Template matching
* Thresholding
* Deep learning
## Library:
* OpenCV
* NumPy
* imutils
* Keras
## Data:
- Our own recording of pictures/videos of several hand gestures such as rock, scissors, paper in different resolution
- Hand gesture recognition database (Grayscale): https://www.kaggle.com/gti-upm/leapgestrecog
- Hand gesture database (Color): https://www.gti.ssr.upm.es/data/HandGesture_database.html
- Static Hand Gesture ASL dataset from IEEE (Video): https://ieee-dataport.org/open-access/static-hand-gesture-asl-dataset
### Optional Dataset:
* https://www.kaggle.com/datamunge/sign-language-mnist#amer_sign2.png
* https://lttm.dei.unipd.it/downloads/gesture/
* http://www-rech.telecom-lille.fr/DHGdataset/
## Delivery Plans:
* Week 1: Implement video/image recognition using open CV 
* Week 2: Apply computer vision theories to interpret the images/videos
* Week 3: Testing and writing a report. 
* Expected Results:
Recognize the input hand gesture from the image/ video stream
Interpreting the meaning of the gesture

